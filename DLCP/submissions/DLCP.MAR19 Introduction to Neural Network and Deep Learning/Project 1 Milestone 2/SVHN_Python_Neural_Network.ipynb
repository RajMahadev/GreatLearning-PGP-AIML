{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVHN Python Neural Network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "3yPmtjOZ9iAS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build a simple Neural Network on SVHN dataset"
      ]
    },
    {
      "metadata": {
        "id": "8aMczb_M9iAU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Import the data from drive"
      ]
    },
    {
      "metadata": {
        "id": "Li_VjN5V9iAY",
        "colab_type": "code",
        "outputId": "ef1b6d0f-bce2-4dfe-ac1c-524446aee8b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "W7hTYAq49iAc",
        "colab_type": "code",
        "outputId": "574b43df-658a-423e-973f-1673e6482470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Open the file as readonly\n",
        "\n",
        "h5f = h5py.File('/content/drive/My Drive/DLCP/Project-1/Data/SVHN_single_grey1.h5', 'r')\n",
        "\n",
        "# Load the training, test and validation set\n",
        "x_train = h5f['X_train'][:]\n",
        "y_train = h5f['y_train'][:]\n",
        "x_test = h5f['X_test'][:]\n",
        "y_test = h5f['y_test'][:]\n",
        "\n",
        "\n",
        "# Close this file\n",
        "h5f.close()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 1024)\n",
        "x_test = x_test.reshape(x_test.shape[0], 1024)\n",
        "\n",
        "# # normalize inputs from 0-255 to 0-1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "print('Training set', x_train.shape, y_train.shape)\n",
        "print('Test set', x_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Training set', (42000, 1024), (42000,))\n",
            "('Test set', (18000, 1024), (18000,))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "goHuC8B29iAo",
        "colab_type": "code",
        "outputId": "7e72bf50-62e5-4c9e-92d8-5100fccc6069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 1024)\n",
            "(42000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "asxNv6KU9iAt",
        "colab_type": "code",
        "outputId": "17000196-1b72-4d29-9b51-3ebee86d8b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18000, 1024)\n",
            "(18000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hN0-qf9S9iA0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Neural network from scratch"
      ]
    },
    {
      "metadata": {
        "id": "g0Th8EjI9iA5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Fully Connected Layer (Linear Layer)"
      ]
    },
    {
      "metadata": {
        "id": "xc_-vf849iA6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fully Connected Layer\n",
        "\n",
        "class Linear():\n",
        "  \"\"\"\n",
        "  Fully Connected Layer\n",
        "  \"\"\"\n",
        "  def __init__(self, input_size, output_size):\n",
        "    self.W = np.random.randn(input_size, output_size) * 0.01 # random weights\n",
        "    self.b = np.zeros((1, output_size)) # random bias\n",
        "    self.params = [self.W, self.b] # list of parameters\n",
        "    self.gradW = None # gradient of weights\n",
        "    self.gradB = None # gradient of bias\n",
        "    self.gradInput = None\n",
        "  \n",
        "  def forward(self, X):\n",
        "    self.X = X\n",
        "    # output = X.W + b\n",
        "    self.output = np.dot(X, self.W) + self.b\n",
        "    return self.output\n",
        "  \n",
        "  def backward(self, nextgrad):\n",
        "    self.gradW = np.dot(self.X.T, nextgrad) # gradW = transpose(X).nextgrad\n",
        "    self.gradB = np.sum(nextgrad, axis=0)\n",
        "    self.gradInput = np.dot(nextgrad, self.W.T)\n",
        "    return self.gradInput, [self.gradW, self.gradB]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jb10UoC29iA9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Rectified Linear Activation Layer (ReLU)\n"
      ]
    },
    {
      "metadata": {
        "id": "zN94HaLS9iA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ReLU():\n",
        "  \"\"\"\n",
        "  Rectified Linear Activation Layer (ReLU)\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    self.params = [] # list of parameters\n",
        "    self.gradInput = None\n",
        "\n",
        "  def forward(self, X):\n",
        "    # relu(x) = np.max(0, x)\n",
        "    self.output = np.maximum(X, 0)\n",
        "    return self.output\n",
        "\n",
        "  def backward(self, nextgrad):\n",
        "    self.gradInput = nextgrad.copy()\n",
        "    self.gradInput[self.output <=0] = 0\n",
        "    return self.gradInput, []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8sOUYyVq9iBD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Define softmax function"
      ]
    },
    {
      "metadata": {
        "id": "wTuaLMW_9iBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Softmax():\n",
        "  \"\"\"\n",
        "  Softmax Activation Function\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    self.params = []\n",
        "    self.gradInput = None\n",
        "\n",
        "  def forward(self, X):\n",
        "    exp_x = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
        "    self.output = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "    return self.output\n",
        "\n",
        "  def backward(self, nextgrad):\n",
        "    self.gradInput = nextgrad.copy()\n",
        "    self.gradInput[self.output <=0] = 0\n",
        "    return self.gradInput, []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UN9RUXPs9iBK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Define the Cross Entropy Loss"
      ]
    },
    {
      "metadata": {
        "id": "wdw3k6a89iBN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CrossEntropy:\n",
        "  def forward(self, X, y):\n",
        "    self.m = y.shape[0]\n",
        "    self.p = softmax(X)\n",
        "    cross_entropy = -np.log(self.p[range(self.m), y]+1e-16)\n",
        "    loss = np.sum(cross_entropy) / self.m\n",
        "    return loss\n",
        "\n",
        "  def backward(self, X, y):\n",
        "    y_idx = y.argmax()        \n",
        "    grad = softmax(X)\n",
        "    grad[range(self.m), y] -= 1\n",
        "    grad /= self.m\n",
        "    return grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3WGzkZ-y9iBP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Define the container NN class that enables the forward prop and backward propagation of the entire network. Note, how this class enables us to add layers of different types and also correctly pass gradients using the chain rule."
      ]
    },
    {
      "metadata": {
        "id": "36Lb_DJu9iBS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NN():\n",
        "  def __init__(self, lossfunc=CrossEntropy(), mode='train'):\n",
        "    self.params = []\n",
        "    self.layers = []\n",
        "    self.loss_func = lossfunc\n",
        "    self.grads = []\n",
        "    self.mode = mode\n",
        "\n",
        "  def add_layer(self, layer):\n",
        "    self.layers.append(layer)\n",
        "    self.params.append(layer.params)\n",
        "\n",
        "  def forward(self, X):\n",
        "    for layer in self.layers:\n",
        "        X = layer.forward(X)\n",
        "    return X\n",
        "\n",
        "  def backward(self, nextgrad):\n",
        "    self.clear_grad_param()\n",
        "    for layer in reversed(self.layers):\n",
        "        nextgrad, grad = layer.backward(nextgrad)\n",
        "        self.grads.append(grad)\n",
        "    return self.grads\n",
        "\n",
        "  def train_step(self, X, y):\n",
        "    out = self.forward(X)\n",
        "    loss = self.loss_func.forward(out,y)\n",
        "    nextgrad = self.loss_func.backward(out,y)\n",
        "    grads = self.backward(nextgrad)\n",
        "    return loss, grads\n",
        "\n",
        "  def predict(self, X):\n",
        "    X = self.forward(X)\n",
        "    p = softmax(X)\n",
        "    return np.argmax(p, axis=1)\n",
        "\n",
        "  def predict_scores(self, X):\n",
        "    X = self.forward(X)\n",
        "    p = softmax(X)\n",
        "    return p\n",
        "\n",
        "  def clear_grad_param(self):\n",
        "    self.grads = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2__dsgXM9iBY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Define the update function (SGD with momentum)"
      ]
    },
    {
      "metadata": {
        "id": "Qc40BqbW9iBb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def update_params(velocity, params, grads, learning_rate=0.01, mu=0.9):\n",
        "  for v, p, g, in zip(velocity, params, reversed(grads)):\n",
        "    for i in range(len(g)):\n",
        "      v[i] = mu * v[i] - learning_rate * g[i]\n",
        "      p[i] += v[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0pdp62ub9iBe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Define a function which gives us the minibatches (both the datapoint and the corresponding label)"
      ]
    },
    {
      "metadata": {
        "id": "wDrrQQ789iBf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get minibatches\n",
        "def minibatch(X, y, minibatch_size):\n",
        "  n = X.shape[0]\n",
        "  minibatches = []\n",
        "  permutation = np.random.permutation(X.shape[0])\n",
        "  X = X[permutation]\n",
        "  y = y[permutation]\n",
        "\n",
        "  for i in range(0, n , minibatch_size):\n",
        "    X_batch = X[i:i + minibatch_size, :]\n",
        "    y_batch = y[i:i + minibatch_size, ]\n",
        "    minibatches.append((X_batch, y_batch))\n",
        "\n",
        "  return minibatches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xflX6m_Y9iBi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### The traning loop"
      ]
    },
    {
      "metadata": {
        "id": "sQTCQ3Cv9iBl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu=0.9, X_val=None, y_val=None):\n",
        "  val_loss_epoch = []\n",
        "  minibatches = minibatch(X_train, y_train, minibatch_size)\n",
        "  minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
        "\n",
        "\n",
        "  for i in range(epoch):\n",
        "      loss_batch = []\n",
        "      val_loss_batch = []\n",
        "      velocity = []\n",
        "      for param_layer in net.params:\n",
        "          p = [np.zeros_like(param) for param in list(param_layer)]\n",
        "          velocity.append(p)\n",
        "\n",
        "      # iterate over mini batches\n",
        "      for X_mini, y_mini in minibatches:\n",
        "          loss, grads = net.train_step(X_mini, y_mini)\n",
        "          loss_batch.append(loss)\n",
        "          update_params(velocity, net.params, grads, learning_rate=learning_rate, mu=mu)\n",
        "\n",
        "      for X_mini_val, y_mini_val in minibatches_val:\n",
        "          val_loss, _ = net.train_step(X_mini, y_mini)\n",
        "          val_loss_batch.append(val_loss)\n",
        "\n",
        "      # accuracy of model at end of epoch after all mini batch updates\n",
        "      m_train = X_train.shape[0]\n",
        "      m_val = X_val.shape[0]\n",
        "      y_train_pred = np.array([], dtype=\"int64\")\n",
        "      y_val_pred = np.array([], dtype=\"int64\")\n",
        "      y_train1 = []\n",
        "      y_vall = []\n",
        "      for i in range(0, m_train, minibatch_size):\n",
        "          X_tr = X_train[i:i + minibatch_size, : ]\n",
        "          y_tr = y_train[i:i + minibatch_size,]\n",
        "          y_train1 = np.append(y_train1, y_tr)\n",
        "          y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
        "\n",
        "      for i in range(0, m_val, minibatch_size):\n",
        "          X_va = X_val[i:i + minibatch_size, : ]\n",
        "          y_va = y_val[i:i + minibatch_size,]\n",
        "          y_vall = np.append(y_vall, y_va)\n",
        "          y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
        "\n",
        "      train_acc = check_accuracy(y_train1, y_train_pred)\n",
        "      val_acc = check_accuracy(y_vall, y_val_pred)\n",
        "\n",
        "      mean_train_loss = sum(loss_batch) / float(len(loss_batch))\n",
        "      mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
        "\n",
        "      val_loss_epoch.append(mean_val_loss)\n",
        "      print(\"Loss = {0} | Training Accuracy = {1} | Val Loss = {2} | Val Accuracy = {3}\".format(mean_train_loss, train_acc, mean_val_loss, val_acc))\n",
        "  return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Jzysxvc9iBs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Write a function to check the accuracy of the model "
      ]
    },
    {
      "metadata": {
        "id": "R8OX7xMX9iBu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def check_accuracy(y_true, y_pred):\n",
        "    return np.mean(y_pred == y_true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jWZlYxlK9iBz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Invoke all that we have created until now and build a 2 linear layer Neural Network with first activation function as ReLU and second as Softmax and loss function as Cross Entropy."
      ]
    },
    {
      "metadata": {
        "id": "5iywv27c9iB6",
        "colab_type": "code",
        "outputId": "a1222e28-2766-4d55-df4b-16d61959f25f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "\n",
        "## input size\n",
        "input_dim = x_train.shape[1]\n",
        "\n",
        "## hyperparameters\n",
        "iterations = 10\n",
        "learning_rate = 1e4\n",
        "hidden_nodes = 32\n",
        "output_nodes = 10\n",
        "\n",
        "## define neural net\n",
        "nn = NN(lossfunc=CrossEntropy())\n",
        "nn.add_layer(Linear(input_dim, hidden_nodes))\n",
        "nn.add_layer(ReLU())\n",
        "nn.add_layer(Linear(hidden_nodes, output_nodes))\n",
        "nn.add_layer(Softmax())\n",
        "\n",
        "nn = train(nn, x_train , y_train, minibatch_size=32, epoch=iterations, \\\n",
        "           learning_rate=learning_rate, X_val=x_test, y_val=y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss = 2.36100775807 | Training Accuracy = 0.0999285714286 | Val Loss = 2.33615017173 | Val Accuracy = 0.100166666667\n",
            "Loss = 2.36167930774 | Training Accuracy = 0.0997142857143 | Val Loss = 2.27365017173 | Val Accuracy = 0.100666666667\n",
            "Loss = 2.35952177577 | Training Accuracy = 0.0997142857143 | Val Loss = 2.27365017173 | Val Accuracy = 0.100666666667\n",
            "Loss = 2.36337394532 | Training Accuracy = 0.0997142857143 | Val Loss = 2.27365017173 | Val Accuracy = 0.100666666667\n",
            "Loss = 2.36057835339 | Training Accuracy = 0.0999285714286 | Val Loss = 2.33615017173 | Val Accuracy = 0.100166666667\n",
            "Loss = 2.35988647946 | Training Accuracy = 0.101928571429 | Val Loss = 2.39865017173 | Val Accuracy = 0.0955\n",
            "Loss = 2.3615460884 | Training Accuracy = 0.0998095238095 | Val Loss = 2.33615017173 | Val Accuracy = 0.100444444444\n",
            "Loss = 2.36129961857 | Training Accuracy = 0.100761904762 | Val Loss = 2.27365017173 | Val Accuracy = 0.0982222222222\n",
            "Loss = 2.36145506686 | Training Accuracy = 0.0998095238095 | Val Loss = 2.33615017173 | Val Accuracy = 0.100444444444\n",
            "Loss = 2.3585082169 | Training Accuracy = 0.0997142857143 | Val Loss = 2.27365017173 | Val Accuracy = 0.100666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KkGmyPeM9iCF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### fprop a single image and showing its prediction"
      ]
    },
    {
      "metadata": {
        "id": "RyPvkKrS9iCL",
        "colab_type": "code",
        "outputId": "23fdb39f-2f38-44cb-98d9-6eadc473b42e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[2].reshape(32, 32), cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f071e587e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sR1IrEGgmGDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Predict Scores for each class\n",
        "prediction = nn.predict_scores(x_test[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uN8QcdG6mKSx",
        "colab_type": "code",
        "outputId": "0f157deb-4323-4d8d-a51c-c79c3b8e94a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "print \"Scores\"\n",
        "print prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores\n",
            "[[0.08533674 0.08533674 0.08533674 0.08533674 0.08533674 0.08533674\n",
            "  0.08533674 0.08533674 0.23196932 0.08533674]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IMJdvG7imMQW",
        "colab_type": "code",
        "outputId": "e2d73b6c-cc48-4825-dd42-5898ed951f5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.argmax(prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "6B3W2tSimNjh",
        "colab_type": "code",
        "outputId": "990f1b20-38af-4411-b8be-d9a0e78f585c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predict_class = nn.predict(x_test[2])[0]\n",
        "predict_class"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "n4BG3nzNmOUi",
        "colab_type": "code",
        "outputId": "867ac493-e5dd-4962-bdba-0b03fef0cec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Original class\n",
        "y_test[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    }
  ]
}